nohup: ignoring input
Start training ...
ESPnet is not installed, cannot use espnet_hubert upstream
ESPnet is not installed, cannot use espnet_hubert upstream
ESPnet is not installed, cannot use espnet_hubert upstream
ESPnet is not installed, cannot use espnet_hubert upstream
[ INFO : 2024-09-25 10:44:47,909 ] - training on multiple gpus, this gpu 0
[ INFO : 2024-09-25 10:44:47,909 ] - training on multiple gpus, this gpu 2
[ INFO : 2024-09-25 10:44:47,909 ] - training on multiple gpus, this gpu 3
[ INFO : 2024-09-25 10:44:47,909 ] - training on multiple gpus, this gpu 1
[ INFO : 2024-09-25 10:44:47,909 ] - exp_dir is: exp/240925_ECAPA_TDNN_GLOB_c512_ASTP_emb192_WavLM_Large_frozen_num_frms150_aug06_spTrue_saFalse_ArcMargin_intertopk_subcenter_SGD_e150
[ INFO : 2024-09-25 10:44:47,909 ] - <== Passed Arguments ==>
[ INFO : 2024-09-25 10:44:47,910 ] - {'data_type': 'shard',
[ INFO : 2024-09-25 10:44:47,910 ] -  'dataloader_args': {'batch_size': 384,
[ INFO : 2024-09-25 10:44:47,910 ] -                      'drop_last': True,
[ INFO : 2024-09-25 10:44:47,910 ] -                      'num_workers': 16,
[ INFO : 2024-09-25 10:44:47,910 ] -                      'pin_memory': False,
[ INFO : 2024-09-25 10:44:47,911 ] -                      'prefetch_factor': 16},
[ INFO : 2024-09-25 10:44:47,911 ] -  'dataset_args': {'aug_prob': 0.6,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'cmvn': True,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'cmvn_args': {'norm_mean': True, 'norm_var': False},
[ INFO : 2024-09-25 10:44:47,911 ] -                   'filter': True,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'filter_args': {'max_num_frames': 400, 'min_num_frames': 50},
[ INFO : 2024-09-25 10:44:47,911 ] -                   'frontend': 's3prl',
[ INFO : 2024-09-25 10:44:47,911 ] -                   'num_frms': 150,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'resample_rate': 16000,
[ INFO : 2024-09-25 10:44:47,911 ] -                   's3prl_args': {'download_dir': './s3prl_hub',
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'frame_length': 20,
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'frame_shift': 20,
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'frozen': True,
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'layer': -1,
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'multilayer_feature': True,
[ INFO : 2024-09-25 10:44:47,911 ] -                                  'upstream_args': {'name': 'wavlm_large'}},
[ INFO : 2024-09-25 10:44:47,911 ] -                   'sample_num_per_epoch': 0,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'shuffle': True,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'shuffle_args': {'shuffle_size': 2500},
[ INFO : 2024-09-25 10:44:47,911 ] -                   'spec_aug': False,
[ INFO : 2024-09-25 10:44:47,911 ] -                   'spec_aug_args': {'max_f': 8,
[ INFO : 2024-09-25 10:44:47,911 ] -                                     'max_t': 10,
[ INFO : 2024-09-25 10:44:47,911 ] -                                     'num_f_mask': 1,
[ INFO : 2024-09-25 10:44:47,911 ] -                                     'num_t_mask': 1,
[ INFO : 2024-09-25 10:44:47,911 ] -                                     'prob': 0.6},
[ INFO : 2024-09-25 10:44:47,911 ] -                   'speed_perturb': True},
[ INFO : 2024-09-25 10:44:47,912 ] -  'enable_amp': True,
[ INFO : 2024-09-25 10:44:47,912 ] -  'exp_dir': 'exp/240925_ECAPA_TDNN_GLOB_c512_ASTP_emb192_WavLM_Large_frozen_num_frms150_aug06_spTrue_saFalse_ArcMargin_intertopk_subcenter_SGD_e150',
[ INFO : 2024-09-25 10:44:47,912 ] -  'gpus': [0, 1, 2, 3],
[ INFO : 2024-09-25 10:44:47,912 ] -  'log_batch_interval': 100,
[ INFO : 2024-09-25 10:44:47,912 ] -  'loss': 'CrossEntropyLoss',
[ INFO : 2024-09-25 10:44:47,912 ] -  'loss_args': {},
[ INFO : 2024-09-25 10:44:47,912 ] -  'margin_scheduler': 'MarginScheduler',
[ INFO : 2024-09-25 10:44:47,913 ] -  'margin_update': {'final_margin': 0.2,
[ INFO : 2024-09-25 10:44:47,913 ] -                    'fix_start_epoch': 40,
[ INFO : 2024-09-25 10:44:47,913 ] -                    'increase_start_epoch': 20,
[ INFO : 2024-09-25 10:44:47,913 ] -                    'increase_type': 'exp',
[ INFO : 2024-09-25 10:44:47,913 ] -                    'initial_margin': 0.0,
[ INFO : 2024-09-25 10:44:47,913 ] -                    'update_margin': True},
[ INFO : 2024-09-25 10:44:47,913 ] -  'model': 'ECAPA_TDNN_GLOB_c512',
[ INFO : 2024-09-25 10:44:47,913 ] -  'model_args': {'embed_dim': 192, 'feat_dim': -1, 'pooling_func': 'ASTP'},
[ INFO : 2024-09-25 10:44:47,913 ] -  'model_init': None,
[ INFO : 2024-09-25 10:44:47,913 ] -  'noise_data': '/scratch/users/astar/bmsi/liut1/data/VoxForWe/musan/lmdb',
[ INFO : 2024-09-25 10:44:47,913 ] -  'num_avg': 10,
[ INFO : 2024-09-25 10:44:47,913 ] -  'num_epochs': 150,
[ INFO : 2024-09-25 10:44:47,913 ] -  'optimizer': 'SGD',
[ INFO : 2024-09-25 10:44:47,913 ] -  'optimizer_args': {'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0001},
[ INFO : 2024-09-25 10:44:47,913 ] -  'projection_args': {'easy_margin': False,
[ INFO : 2024-09-25 10:44:47,913 ] -                      'project_type': 'arc_margin_intertopk_subcenter',
[ INFO : 2024-09-25 10:44:47,913 ] -                      'scale': 32.0},
[ INFO : 2024-09-25 10:44:47,913 ] -  'reverb_data': '/scratch/users/astar/bmsi/liut1/data/VoxForWe/rirs/lmdb',
[ INFO : 2024-09-25 10:44:47,914 ] -  'save_epoch_interval': 5,
[ INFO : 2024-09-25 10:44:47,914 ] -  'scheduler': 'ExponentialDecrease',
[ INFO : 2024-09-25 10:44:47,914 ] -  'scheduler_args': {'final_lr': 1e-05,
[ INFO : 2024-09-25 10:44:47,914 ] -                     'initial_lr': 0.1,
[ INFO : 2024-09-25 10:44:47,914 ] -                     'warm_from_zero': True,
[ INFO : 2024-09-25 10:44:47,914 ] -                     'warm_up_epoch': 6},
[ INFO : 2024-09-25 10:44:47,914 ] -  'seed': 42,
[ INFO : 2024-09-25 10:44:47,914 ] -  'train_data': '/scratch/users/astar/bmsi/liut1/data/VoxForWe/vox2_dev/shard.list',
[ INFO : 2024-09-25 10:44:47,914 ] -  'train_label': '/scratch/users/astar/bmsi/liut1/data/VoxForWe/vox2_dev/utt2spk'}
[ INFO : 2024-09-25 10:44:50,015 ] - <== Data statistics ==>
[ INFO : 2024-09-25 10:44:50,015 ] - train data num: 1092009, spk num: 5994
[ INFO : 2024-09-25 10:44:50,582 ] - <== Dataloaders ==>
[ INFO : 2024-09-25 10:44:50,582 ] - train dataloaders created
[ INFO : 2024-09-25 10:44:50,582 ] - <== Model ==>
[ INFO : 2024-09-25 10:44:50,582 ] - <== Model ==>
[ INFO : 2024-09-25 10:44:50,582 ] - epoch iteration number: 710
[ INFO : 2024-09-25 10:44:50,582 ] - <== Model ==>
[ INFO : 2024-09-25 10:44:50,582 ] - <== Model ==>
[ INFO : 2024-09-25 10:44:50,583 ] - Requesting URL: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt
[ INFO : 2024-09-25 10:44:50,583 ] - Requesting URL: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt
[ INFO : 2024-09-25 10:44:50,583 ] - Requesting URL: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt
[ DEBUG : 2024-09-25 10:44:50,583 ] - Attempting to acquire lock 23278496361488 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,583 ] - Attempting to acquire lock 22503528835152 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,583 ] - Attempting to acquire lock 23336473760960 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ INFO : 2024-09-25 10:44:50,583 ] - Requesting URL: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt
[ DEBUG : 2024-09-25 10:44:50,583 ] - Attempting to acquire lock 23422334654928 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,585 ] - Lock 23336473760960 acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,585 ] - Lock 23278496361488 not acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock, waiting 0.05 seconds ...
[ DEBUG : 2024-09-25 10:44:50,585 ] - Lock 23422334654928 not acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock, waiting 0.05 seconds ...
[ DEBUG : 2024-09-25 10:44:50,585 ] - Lock 22503528835152 not acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock, waiting 0.05 seconds ...
[ DEBUG : 2024-09-25 10:44:50,585 ] - Attempting to release lock 23336473760960 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,586 ] - Lock 23336473760960 released on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ INFO : 2024-09-25 10:44:50,586 ] - Using URL's local file: s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt
[ DEBUG : 2024-09-25 10:44:50,635 ] - Attempting to acquire lock 23422334654928 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Attempting to acquire lock 23278496361488 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Attempting to acquire lock 22503528835152 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Lock 23422334654928 acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Attempting to release lock 23422334654928 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Lock 23422334654928 released on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,635 ] - Lock 23278496361488 not acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock, waiting 0.05 seconds ...
[ INFO : 2024-09-25 10:44:50,635 ] - Using URL's local file: s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt
[ DEBUG : 2024-09-25 10:44:50,635 ] - Lock 22503528835152 acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,636 ] - Attempting to release lock 22503528835152 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,636 ] - Lock 22503528835152 released on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ INFO : 2024-09-25 10:44:50,636 ] - Using URL's local file: s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt
[ DEBUG : 2024-09-25 10:44:50,685 ] - Attempting to acquire lock 23278496361488 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,686 ] - Lock 23278496361488 acquired on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,686 ] - Attempting to release lock 23278496361488 on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ DEBUG : 2024-09-25 10:44:50,686 ] - Lock 23278496361488 released on s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt.lock
[ INFO : 2024-09-25 10:44:50,686 ] - Using URL's local file: s3prl_hub/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt
[ INFO : 2024-09-25 10:44:53,911 ] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[ INFO : 2024-09-25 10:44:53,911 ] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[ INFO : 2024-09-25 10:44:53,911 ] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[ INFO : 2024-09-25 10:44:53,912 ] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[ INFO : 2024-09-25 10:44:59,947 ] - Train model from scratch ...
[ INFO : 2024-09-25 10:44:59,948 ] - Train model from scratch ...
[ INFO : 2024-09-25 10:44:59,957 ] - speaker_model size: 324060505
[ INFO : 2024-09-25 10:44:59,957 ] - Train model from scratch ...
[ INFO : 2024-09-25 10:44:59,975 ] - Train model from scratch ...
[ INFO : 2024-09-25 10:44:59,992 ] - start_epoch: 1
[ INFO : 2024-09-25 10:44:59,993 ] - start_epoch: 1
[ INFO : 2024-09-25 10:45:00,003 ] - ECAPA_TDNN(
[ INFO : 2024-09-25 10:45:00,003 ] -   (layer1): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,004 ] -     (conv): Conv1d(1024, 512, kernel_size=(5,), stride=(1,), padding=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -     (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -   )
[ INFO : 2024-09-25 10:45:00,004 ] -   (layer2): SE_Res2Block(
[ INFO : 2024-09-25 10:45:00,004 ] -     (se_res2block): Sequential(
[ INFO : 2024-09-25 10:45:00,004 ] -       (0): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,004 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,004 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -       )
[ INFO : 2024-09-25 10:45:00,004 ] -       (1): Res2Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,004 ] -         (convs): ModuleList(
[ INFO : 2024-09-25 10:45:00,004 ] -           (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -           (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
[ INFO : 2024-09-25 10:45:00,004 ] -         )
[ INFO : 2024-09-25 10:45:00,004 ] -         (bns): ModuleList(
[ INFO : 2024-09-25 10:45:00,004 ] -           (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -           (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,004 ] -         )
[ INFO : 2024-09-25 10:45:00,004 ] -       )
[ INFO : 2024-09-25 10:45:00,004 ] -       (2): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,005 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,005 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -       )
[ INFO : 2024-09-25 10:45:00,005 ] -       (3): SE_Connect(
[ INFO : 2024-09-25 10:45:00,005 ] -         (linear1): Linear(in_features=512, out_features=128, bias=True)
[ INFO : 2024-09-25 10:45:00,005 ] -         (linear2): Linear(in_features=128, out_features=512, bias=True)
[ INFO : 2024-09-25 10:45:00,005 ] -       )
[ INFO : 2024-09-25 10:45:00,005 ] -     )
[ INFO : 2024-09-25 10:45:00,005 ] -   )
[ INFO : 2024-09-25 10:45:00,005 ] -   (layer3): SE_Res2Block(
[ INFO : 2024-09-25 10:45:00,005 ] -     (se_res2block): Sequential(
[ INFO : 2024-09-25 10:45:00,005 ] -       (0): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,005 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,005 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -       )
[ INFO : 2024-09-25 10:45:00,005 ] -       (1): Res2Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,005 ] -         (convs): ModuleList(
[ INFO : 2024-09-25 10:45:00,005 ] -           (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -           (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
[ INFO : 2024-09-25 10:45:00,005 ] -         )
[ INFO : 2024-09-25 10:45:00,005 ] -         (bns): ModuleList(
[ INFO : 2024-09-25 10:45:00,005 ] -           (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -           (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -           (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -           (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,005 ] -           (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,006 ] -           (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,006 ] -           (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,006 ] -         )
[ INFO : 2024-09-25 10:45:00,006 ] -       )
[ INFO : 2024-09-25 10:45:00,006 ] -       (2): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,006 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,006 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,006 ] -       )
[ INFO : 2024-09-25 10:45:00,006 ] -       (3): SE_Connect(
[ INFO : 2024-09-25 10:45:00,006 ] -         (linear1): Linear(in_features=512, out_features=128, bias=True)
[ INFO : 2024-09-25 10:45:00,006 ] -         (linear2): Linear(in_features=128, out_features=512, bias=True)
[ INFO : 2024-09-25 10:45:00,006 ] -       )
[ INFO : 2024-09-25 10:45:00,006 ] -     )
[ INFO : 2024-09-25 10:45:00,006 ] -   )
[ INFO : 2024-09-25 10:45:00,006 ] -   (layer4): SE_Res2Block(
[ INFO : 2024-09-25 10:45:00,006 ] -     (se_res2block): Sequential(
[ INFO : 2024-09-25 10:45:00,006 ] -       (0): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,006 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,006 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,006 ] -       )
[ INFO : 2024-09-25 10:45:00,006 ] -       (1): Res2Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,006 ] -         (convs): ModuleList(
[ INFO : 2024-09-25 10:45:00,006 ] -           (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -           (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
[ INFO : 2024-09-25 10:45:00,006 ] -         )
[ INFO : 2024-09-25 10:45:00,006 ] -         (bns): ModuleList(
[ INFO : 2024-09-25 10:45:00,007 ] -           (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -           (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -         )
[ INFO : 2024-09-25 10:45:00,007 ] -       )
[ INFO : 2024-09-25 10:45:00,007 ] -       (2): Conv1dReluBn(
[ INFO : 2024-09-25 10:45:00,007 ] -         (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,007 ] -         (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -       )
[ INFO : 2024-09-25 10:45:00,007 ] -       (3): SE_Connect(
[ INFO : 2024-09-25 10:45:00,007 ] -         (linear1): Linear(in_features=512, out_features=128, bias=True)
[ INFO : 2024-09-25 10:45:00,007 ] -         (linear2): Linear(in_features=128, out_features=512, bias=True)
[ INFO : 2024-09-25 10:45:00,007 ] -       )
[ INFO : 2024-09-25 10:45:00,007 ] -     )
[ INFO : 2024-09-25 10:45:00,007 ] -   )
[ INFO : 2024-09-25 10:45:00,007 ] -   (conv): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,007 ] -   (pool): ASTP(
[ INFO : 2024-09-25 10:45:00,007 ] -     (linear1): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,007 ] -     (linear2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
[ INFO : 2024-09-25 10:45:00,007 ] -   )
[ INFO : 2024-09-25 10:45:00,007 ] -   (bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
[ INFO : 2024-09-25 10:45:00,007 ] -   (linear): Linear(in_features=3072, out_features=192, bias=True)
[ INFO : 2024-09-25 10:45:00,007 ] -   (bn2): Identity()
[ INFO : 2024-09-25 10:45:00,007 ] -   (frontend): S3prlFrontend(
[ INFO : 2024-09-25 10:45:00,007 ] -     (upstream): S3PRLUpstream(
[ INFO : 2024-09-25 10:45:00,007 ] -       (upstream): UpstreamExpert(
[ INFO : 2024-09-25 10:45:00,007 ] -         (model): WavLM(
[ INFO : 2024-09-25 10:45:00,007 ] -           (feature_extractor): ConvFeatureExtractionModel(
[ INFO : 2024-09-25 10:45:00,008 ] -             (conv_layers): ModuleList(
[ INFO : 2024-09-25 10:45:00,008 ] -               (0): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                 (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,008 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                 )
[ INFO : 2024-09-25 10:45:00,008 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,008 ] -               )
[ INFO : 2024-09-25 10:45:00,008 ] -               (1): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                 (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,008 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                 )
[ INFO : 2024-09-25 10:45:00,008 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,008 ] -               )
[ INFO : 2024-09-25 10:45:00,008 ] -               (2): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                 (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,008 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,008 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,008 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,008 ] -                 )
[ INFO : 2024-09-25 10:45:00,008 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,008 ] -               )
[ INFO : 2024-09-25 10:45:00,008 ] -               (3): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                 (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,009 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                 )
[ INFO : 2024-09-25 10:45:00,009 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,009 ] -               )
[ INFO : 2024-09-25 10:45:00,009 ] -               (4): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                 (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,009 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                 )
[ INFO : 2024-09-25 10:45:00,009 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,009 ] -               )
[ INFO : 2024-09-25 10:45:00,009 ] -               (5): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                 (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,009 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,009 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,009 ] -                 )
[ INFO : 2024-09-25 10:45:00,009 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,009 ] -               )
[ INFO : 2024-09-25 10:45:00,009 ] -               (6): Sequential(
[ INFO : 2024-09-25 10:45:00,009 ] -                 (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
[ INFO : 2024-09-25 10:45:00,010 ] -                 (1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,010 ] -                 (2): Sequential(
[ INFO : 2024-09-25 10:45:00,010 ] -                   (0): TransposeLast()
[ INFO : 2024-09-25 10:45:00,010 ] -                   (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (2): TransposeLast()
[ INFO : 2024-09-25 10:45:00,010 ] -                 )
[ INFO : 2024-09-25 10:45:00,010 ] -                 (3): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,010 ] -               )
[ INFO : 2024-09-25 10:45:00,010 ] -             )
[ INFO : 2024-09-25 10:45:00,010 ] -           )
[ INFO : 2024-09-25 10:45:00,010 ] -           (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -           (dropout_input): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,010 ] -           (dropout_features): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,010 ] -           (encoder): TransformerEncoder(
[ INFO : 2024-09-25 10:45:00,010 ] -             (pos_conv): Sequential(
[ INFO : 2024-09-25 10:45:00,010 ] -               (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
[ INFO : 2024-09-25 10:45:00,010 ] -               (1): SamePad()
[ INFO : 2024-09-25 10:45:00,010 ] -               (2): GELU(approximate='none')
[ INFO : 2024-09-25 10:45:00,010 ] -             )
[ INFO : 2024-09-25 10:45:00,010 ] -             (layers): ModuleList(
[ INFO : 2024-09-25 10:45:00,010 ] -               (0): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,010 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,010 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (relative_attention_bias): Embedding(320, 16)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,010 ] -                 )
[ INFO : 2024-09-25 10:45:00,010 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,011 ] -               )
[ INFO : 2024-09-25 10:45:00,011 ] -               (1): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,011 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,011 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 )
[ INFO : 2024-09-25 10:45:00,011 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,011 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,011 ] -               )
[ INFO : 2024-09-25 10:45:00,011 ] -               (2): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,011 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,012 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                 )
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,012 ] -               )
[ INFO : 2024-09-25 10:45:00,012 ] -               (3): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,012 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,012 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,012 ] -                 )
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,012 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,013 ] -               )
[ INFO : 2024-09-25 10:45:00,013 ] -               (4): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,013 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,013 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 )
[ INFO : 2024-09-25 10:45:00,013 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,013 ] -               )
[ INFO : 2024-09-25 10:45:00,013 ] -               (5): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,013 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,013 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,013 ] -                 )
[ INFO : 2024-09-25 10:45:00,013 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,014 ] -               )
[ INFO : 2024-09-25 10:45:00,014 ] -               (6): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,014 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,014 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 )
[ INFO : 2024-09-25 10:45:00,014 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,014 ] -               )
[ INFO : 2024-09-25 10:45:00,014 ] -               (7): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,014 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,014 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,014 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 )
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,015 ] -               )
[ INFO : 2024-09-25 10:45:00,015 ] -               (8): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,015 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,015 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 )
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,015 ] -               )
[ INFO : 2024-09-25 10:45:00,015 ] -               (9): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,015 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,015 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,015 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 )
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,016 ] -               )
[ INFO : 2024-09-25 10:45:00,016 ] -               (10): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,016 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,016 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 )
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,016 ] -               )
[ INFO : 2024-09-25 10:45:00,016 ] -               (11): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,016 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,016 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,016 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 )
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,017 ] -               )
[ INFO : 2024-09-25 10:45:00,017 ] -               (12): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,017 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,017 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 )
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] - start_epoch: 1
[ INFO : 2024-09-25 10:45:00,017 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,017 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,018 ] -               )
[ INFO : 2024-09-25 10:45:00,018 ] -               (13): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,018 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,018 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                 )
[ INFO : 2024-09-25 10:45:00,018 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,018 ] -               )
[ INFO : 2024-09-25 10:45:00,018 ] -               (14): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,018 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,018 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,018 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 )
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,019 ] -               )
[ INFO : 2024-09-25 10:45:00,019 ] -               (15): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,019 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,019 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 )
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,019 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,020 ] -               )
[ INFO : 2024-09-25 10:45:00,020 ] -               (16): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,020 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,020 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                 )
[ INFO : 2024-09-25 10:45:00,020 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,020 ] -               )
[ INFO : 2024-09-25 10:45:00,020 ] -               (17): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,020 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,020 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,020 ] -                 )
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,021 ] -               )
[ INFO : 2024-09-25 10:45:00,021 ] -               (18): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,021 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,021 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 )
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,021 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,021 ] -               )
[ INFO : 2024-09-25 10:45:00,021 ] -               (19): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,021 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,022 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 )
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,022 ] -               )
[ INFO : 2024-09-25 10:45:00,022 ] -               (20): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,022 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,022 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 )
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,022 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,022 ] -               )
[ INFO : 2024-09-25 10:45:00,022 ] -               (21): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,023 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,023 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 )
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,023 ] -               )
[ INFO : 2024-09-25 10:45:00,023 ] -               (22): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,023 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,023 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 )
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,023 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,024 ] -               )
[ INFO : 2024-09-25 10:45:00,024 ] -               (23): TransformerSentenceEncoderLayer(
[ INFO : 2024-09-25 10:45:00,024 ] -                 (self_attn): MultiheadAttention(
[ INFO : 2024-09-25 10:45:00,024 ] -                   (dropout_module): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,024 ] -                   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                   (grep_linear): Linear(in_features=64, out_features=8, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                 )
[ INFO : 2024-09-25 10:45:00,024 ] -                 (dropout1): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (dropout2): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (dropout3): Dropout(p=0.0, inplace=False)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)
[ INFO : 2024-09-25 10:45:00,024 ] -                 (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,024 ] -               )
[ INFO : 2024-09-25 10:45:00,024 ] -             )
[ INFO : 2024-09-25 10:45:00,024 ] -             (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,024 ] -           )
[ INFO : 2024-09-25 10:45:00,024 ] -           (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
[ INFO : 2024-09-25 10:45:00,024 ] -         )
[ INFO : 2024-09-25 10:45:00,024 ] -       )
[ INFO : 2024-09-25 10:45:00,024 ] -     )
[ INFO : 2024-09-25 10:45:00,024 ] -     (featurizer): Featurizer()
[ INFO : 2024-09-25 10:45:00,024 ] -   )
[ INFO : 2024-09-25 10:45:00,024 ] -   (projection): ArcMarginProduct_intertopk_subcenter(in_features=192, out_features=17982, scale=32.0, margin=0.0, easy_margin=False,K=3, mp=0.06, k_top=5, do_lm=False)
[ INFO : 2024-09-25 10:45:00,024 ] - )
[ INFO : 2024-09-25 10:45:00,024 ] - start_epoch: 1
[ INFO : 2024-09-25 10:45:00,217 ] - <== Loss ==>
[ INFO : 2024-09-25 10:45:00,217 ] - loss criterion is: CrossEntropyLoss
[ INFO : 2024-09-25 10:45:00,219 ] - <== Optimizer ==>
[ INFO : 2024-09-25 10:45:00,219 ] - optimizer is: SGD
[ INFO : 2024-09-25 10:45:00,219 ] - <== Scheduler ==>
[ INFO : 2024-09-25 10:45:00,219 ] - scheduler is: ExponentialDecrease
[ INFO : 2024-09-25 10:45:00,219 ] - <== MarginScheduler ==>
[ INFO : 2024-09-25 10:45:00,225 ] - <========== Training process ==========>
[ INFO : 2024-09-25 10:45:00,225 ] - +----------+----------+----------+----------+----------+----------+
[ INFO : 2024-09-25 10:45:00,225 ] - |     Epoch|     Batch|        Lr|    Margin|      Loss|       Acc|
[ INFO : 2024-09-25 10:45:00,225 ] - +----------+----------+----------+----------+----------+----------+
[ INFO : 2024-09-25 10:46:02,727 ] - Reducer buckets have been rebuilt in this iteration.
[ INFO : 2024-09-25 10:46:02,740 ] - Reducer buckets have been rebuilt in this iteration.
[ INFO : 2024-09-25 10:46:02,748 ] - Reducer buckets have been rebuilt in this iteration.
[ INFO : 2024-09-25 10:46:02,749 ] - Reducer buckets have been rebuilt in this iteration.
[ INFO : 2024-09-25 10:48:05,605 ] - |         1|       100|  0.055299|         0|    9.3462|    1.7604|
[ INFO : 2024-09-25 10:48:05,605 ] - |         1|       100|  0.055299|         0|     9.342|    1.7813|
[ INFO : 2024-09-25 10:48:05,605 ] - |         1|       100|  0.055299|         0|    9.3073|    1.8229|
[ INFO : 2024-09-25 10:48:05,608 ] - |         1|       100|  0.055299|         0|    9.3177|    1.6797|
[ INFO : 2024-09-25 10:50:07,387 ] - |         1|       200|    0.1102|         0|    6.9971|    13.018|
[ INFO : 2024-09-25 10:50:07,387 ] - |         1|       200|    0.1102|         0|    6.9772|    12.779|
[ INFO : 2024-09-25 10:50:07,388 ] - |         1|       200|    0.1102|         0|    6.9818|    13.148|
[ INFO : 2024-09-25 10:50:07,388 ] - |         1|       200|    0.1102|         0|    6.9931|    12.738|
